var documenterSearchIndex = {"docs":
[{"location":"manual/codegen/#man_codegen","page":"Code generation","title":"Code Generation","text":"","category":"section"},{"location":"manual/codegen/","page":"Code generation","title":"Code generation","text":"Allocation free\nShow basic file structure, \nHow to call code ","category":"page"},{"location":"functions/#Functions","page":"Functions","title":"Functions","text":"","category":"section"},{"location":"functions/#LinearMPC.add_constraint!-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.add_constraint!","text":"add_constraint!(mpc::MPC;\n    Ax, Au, Ar, Aw, Ad, Aup,\n    ub, lb, ks, soft, binary, prio)\nadd_constraint!(mpc;Ax,Au,ub,lb,\n                ks, soft, binary,prio)\n\nAdds the constraints lb ≤ Ax xₖ + Au uₖ ≤ ub for the time steps k ∈ ks (additional terms Ar rₖ, Aw wₖ, Ad dₖ, Aup u⁻ₖ are possible)\n\nsoft marks if the constraint should be softened (default false)\nbinary marks if either the upper or lower bounds should be enforced with equality (default false)\nprio marks the relative priority of the constraint (default 0)\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.certify-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.certify","text":"certify(mpc; range, AS0, opts)\n\nProvide certificates on the iteration complexity of DAQP for solving the resulting optimization problems. \n\nrange is the parameter range over which the certification should be done\nAS0 is the starting working set in DAQP (defaults to empty)\nsettings the settings used in the certification (see ASCertain.CertSettings()) \n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.compute_control-Tuple{Union{LinearMPC.ExplicitMPC, LinearMPC.MPC}, Any}","page":"Functions","title":"LinearMPC.compute_control","text":"compute_control(mpc,x;r,uprev)\n\nFor a given MPC mpc and state x, compute the optimal control action.  Optional arguments: \n\nr - reference value\nuprev - previous control action\n\nall of them defaults to zero.\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.move_block!-Tuple{Any, Vector{Int64}}","page":"Functions","title":"LinearMPC.move_block!","text":"move_block!(mpc,block)\n\nReduce the number of controls by keeping it constant in blocks. For example, block=[2,1,3] keeps the control constant for 2 time-steps, 1 time step, and 3 time steps.\n\nif sum(block) ≠ mpc.Nc, the resulting block will be padded or clipped\nif block is an Int, a vector with constant block size is created\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.mpc2mpqp-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.mpc2mpqp","text":"mpc2mpqp(mpc)\n\nFor a given MPC structure mpc, form the multi-parametric QP mpQP. \n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_bounds!-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.set_bounds!","text":"set_bounds!(mpc;umin,umax,ymin,umax)\n\nSets the bounds umin ≤ u ≤ umax and ymin ≤ y ≤ umax\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_horizon!-Tuple{Any}","page":"Functions","title":"LinearMPC.set_horizon!","text":"set_horizon!(mpc;Np,Nc)\n\nSets the prediction horizon Np and control horizon Nc\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_input_bounds!-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.set_input_bounds!","text":"set_input_bounds!(mpc;umin,umax)\n\nSets the input bounds umin ≤ u ≤ umax \n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_labels!-Tuple{Any}","page":"Functions","title":"LinearMPC.set_labels!","text":"set_labels!(mpc;x,u,y,d)\n\nSets the name of the states x, controls u, output u, disturbance d \n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_objective!-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.set_objective!","text":"set_objective!(mpc;Q,R,Rr,S,Qf)\n\nSet the weights in the objective function `xN' C' Qf C xN^T + ∑ (C xₖ - rₖ)' Q (C xₖ - rₖ)  + uₖ' R uₖ + Δuₖ' Rr Δuₖ + xₖ' S uₖ\n\nA vector is interpreted as a diagonal matrix.\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_output_bounds!-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.set_output_bounds!","text":"set_output_bounds!(mpc;ymin,ymax,\n                ks, soft, binary,prio)\n\nAdds the constraints lb ≤ C x  ≤ ub for the time steps k ∈ ks \n\nsoft marks if the constraint should be softened (default false)\nbinary marks if either the upper or lower bounds should be enforced with equality (default false)\nprio marks the relative priority of the constraint (default 0)\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_prestabilizing_feedback!-Tuple{Any, AbstractMatrix}","page":"Functions","title":"LinearMPC.set_prestabilizing_feedback!","text":"set_prestabilizing_feedback!(mpc,K)\n\nSets the prestabilizing feedback K\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_prestabilizing_feedback!-Tuple{Any}","page":"Functions","title":"LinearMPC.set_prestabilizing_feedback!","text":"set_prestabilizing_feedback!(mpc)\n\nSets the prestabilizing feedback K to the infinte horizon LQR gain`\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_terminal_cost!-Tuple{Any}","page":"Functions","title":"LinearMPC.set_terminal_cost!","text":"set_terminal_cost!(mpc)\n\nSets the terminal cost Qf to the inifinite horizon LQR cost \n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.setup!-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.setup!","text":"setup!(mpc)\n\nSets up the mpc given its current parameters and settings   Internally, this means generating an mpQP, and setting up a DAQP workspace.\n\n\n\n\n\n","category":"method"},{"location":"manual/explicit/#man_empc","page":"Explict MPC","title":"Explicit MPC","text":"","category":"section"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"Concept of explicit MPC\nThe solver (ParametricDAQP.jl)\nComputing explicit solution \nParameterRange\nVisualizing Explicit Solution \nGenerating code","category":"page"},{"location":"examples/invpend/#ex_invpned","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"","category":"section"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"To exemplify the basics of LinearMPC.jl, we consider the classical example of controlling a inverted pendulum on a cart. The cart can be moved by applying a force u, to control the cart position p  and pendulum angle theta. The start of using MPC is to have a model of the system we want to control, and the model which is used in an MPC controller is discrete-time state-space models of the form x_k+1 = F x_k G u_k. In ref we discuss more how to use different types of models, but the end-point is always a discrete-time state-space system. For simplicity, we assume that the following state-space model is given for cart system ","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"F = ,\\quad G = ","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"where p and dotp are the position/velocity of the cart, and theta and dottheta are the angle and angular velocity of the pendulum. ","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"Our goal is to control the cart's position p and the angle of the pendulum theta. We denote the signals we want to control with y, which in our case gives y_1 = p and y_2 = theta. How the states relates to our output y can compactly be written as y = Cx, which for the cart system gives ","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"C = ","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"An additional requirement is that we don't want the control signal to be too \"jittery\". This is addressed with a penalty Delta u R_r Delta u, where Delta u denotes the change in the control input between to time steps.  The objective at a single time step, thus becomes (Cx - y)^T Q (Cx-y) + Delta u^T R Delta u.","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"In addition to the dynamics of the system, we also want to impose additional constraint when controlling the system. First, there is a limited amount of force u that can be applied. Specifically, this gives us the following bounds on the control: -2 leq u leq 2. Moreover, we also want the angle theta to not be to large, since this would our model. Therefore, we also have the constraint -02 leq theta leq 02.","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"F = ","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"Taken together, we pose the control problem as a receding horizon control problem. ","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"Control horizon / Prediction horizon (hint at move blocking)","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"Simulate the system","category":"page"},{"location":"examples/invpend/#Generating-C-code","page":"Example - Inverted Pendulum on a Cart","title":"Generating C-code","text":"","category":"section"},{"location":"manual/compcert/#man_compcert","page":"Complexity Certification","title":"Complexity Certification","text":"","category":"section"},{"location":"manual/compcert/","page":"Complexity Certification","title":"Complexity Certification","text":"Real-time MPC\nIdea of mapping\nHow to call certification\nInterpreting result ","category":"page"},{"location":"manual/simulation/#man_simulation","page":"Simulating","title":"Simulating","text":"","category":"section"},{"location":"manual/simulation/","page":"Simulating","title":"Simulating","text":"Simulation class \nRunning simulation\nVisualizing\nCallback","category":"page"},{"location":"manual/moveblock/#man_moveblock","page":"Move blocking ","title":"Move Blocking","text":"","category":"section"},{"location":"manual/model/#man_model","page":"Models","title":"Models","text":"","category":"section"},{"location":"manual/model/","page":"Models","title":"Models","text":"As its name suggests Model Predictive Control uses a predictive model when computing a control action. The models used internally in LinearMPC.jl are discrete-time state-space models of the form ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"x_k+1 = F x_k + G u_k","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"where the state at time step k+1 is a linear combinations of the current state x_k and a control action u_k. If matrices F and G that define such a state-space model is available, a MPC controller that uses that model is created with ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"mpc = LinearMPC.MPC(F,G)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"One can also create a Model struct first, and then create the MPC controller, with ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"model = LinearMPC.Model(F,G)\nmpc = LinearMPC.MPC(model)","category":"page"},{"location":"manual/model/#Continuous-time-models","page":"Models","title":"Continuous-time models","text":"","category":"section"},{"location":"manual/model/","page":"Models","title":"Models","text":"Often, the system dynamics is given in continuous time rather than discrete time. That is, the system dynamics is a state space model of the form ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"fracddt x(t) = A x(t) + B u(t)\n","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"One alternative to deal with this is to discretize the system, to yield matrices F and G instead of A and B. A MPC controller that use a discretized continuous-time model can be created with","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"mpc = LinearMPC.MPC(A,B,Ts)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"where Ts is the sample time, which  and determines how much one time step is. (For example, T_s = 01 corresponds to 10 time steps being 1 second.) As for discrete-time state spaces models, one can first create a Model struct, and create a MPC controller based on this model as follows: ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"model = LinearMPC.Model(A,B,Ts)\nmpc = LinearMPC.MPC(model)","category":"page"},{"location":"manual/model/#Outputs","page":"Models","title":"Outputs","text":"","category":"section"},{"location":"manual/model/","page":"Models","title":"Models","text":"In the MPC, one can make an \"output\" y of the system track a reference r. This \"output\" is a linear combination of the form  ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"y_k = C x_k ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"where C is a matrix that maps the states output. ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"note: Difference to measurements\nIn this context, y is not necessarily what is measured from the system. Instead, it should be thought of quantities that are of interest to be controlled.","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"The output of the system can be set with the  optional argument C. So for the model ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"x_k+1 = F x_k + G u_k quad y_k = C x_k","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"an MPC controller that uses this model can be created with","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"mpc = LinearMPC.MPC(F,G;C)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"or by first creating a Model as ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"model = LinearMPC.Model(F,G;C)\nmpc = LinearMPC.MPC(model)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"Similarly, an MPC controller of the continuous-time system","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"fracddt x(t) = A x(t) + B u(t) quad y(t) = C x(t)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"is setup with ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"mpc = LinearMPC.MPC(A,B,Ts;C)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"or ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"model = LinearMPC.Model(A,B,Ts;C)\nmpc = LinearMPC.MPC(model)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"note: Default value\nIf C is not provided, it is assumed that all of the states are the output (that is, y=x, or, equivalently, C=I.)","category":"page"},{"location":"manual/model/#Disturbances","page":"Models","title":"Disturbances","text":"","category":"section"},{"location":"manual/model/","page":"Models","title":"Models","text":"Models with disturbances d are also supported. Specifically, linear combinations of d is allowed to be additive to the dynamics and to the measurements as  ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"x_k+1 = F x_k + G u_k + G_d d_k quad y_k = C x_k + D_d d_k ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"where the matrices G_d and D_d determines the linear combination for the dynamics and the output, respectively. Both G_d and D_d can be set as optional arguments:","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"mpc = LinearMPC.MPC(F,G;Gd,C,Dd)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"Similarly, continuous-time state space models of the form ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"fracddt x(t) = A x(t) + B u(t) + B_d d(t) quad y(t) = C x(t) + D_d x(t)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"can be used with ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"mpc = LinearMPC.MPC(A,B,Ts;Bd,C,Dd)","category":"page"},{"location":"manual/model/#Linearization","page":"Models","title":"Linearization","text":"","category":"section"},{"location":"manual/model/","page":"Models","title":"Models","text":"For a nonlinear discrete-time state-space model of the form  ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"x_k+1 = f(x_ku_kd_k) quad y_k = h(x_ku_kd_k)    ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"an MPC controller with a linearized model around an operating point x_o, u_o and d_o can be created with ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"model = LinearMPC.Model(f,h,x_o,u_o; d=d_o)\nmpc = LinearMPC.MPC(model)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"Similary, for a nonlinear continuous-time state-space model of the form","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"fracddt x(t) = f(x(t)u(t)d(t)) quad y(t) = h(x(t)u(t)d(t))","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"an MPC controller with a linearized model around an operating point x_o, u_o and d_o can be created with ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"model = LinearMPC.Model(f,h,x_o,u_o,Ts; d=d_o)\nmpc = LinearMPC.MPC(model)","category":"page"},{"location":"manual/model/#Using-ControlSystems.jl","page":"Models","title":"Using ControlSystems.jl","text":"","category":"section"},{"location":"manual/model/","page":"Models","title":"Models","text":"Linear MPC also support system models from ControlSystems.jl. Specifically it supports these types of systems: ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"Transfer functions\nState-space models\nDelayed LTI systems","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"For a system sys created with ControlSystems.jl, an MPC controller can simply created with  ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"mpc = LinearMPC.MPC(sys)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"For example, given the transfer function  ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":" G(s) = frac1s^2+2s+1 ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"and MPC controller using this transfer function as its model can be created with  ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"sys = tf([1.0],[1,2,1])\nmpc = LinearMPC.MPC(sys)","category":"page"},{"location":"manual/solver/#man_solver","page":"Solver Settings","title":"Solver Settings","text":"","category":"section"},{"location":"manual/solver/","page":"Solver Settings","title":"Solver Settings","text":"Generated code\nPrecision\nTolerances\nIteration limits","category":"page"},{"location":"manual/simple/#man_simple","page":"Simple example","title":"Simple Example","text":"","category":"section"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"A simplified form of the MPC problem that LinearMPC.jl solves is","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"beginaligned\n        undersetu_0dotsu_N-1textminimize textcolorblackfrac12sum_k=0^N-1 left((Cx_k-r)^T Q (C x_k-r) + u_k^T R u_k + Delta u_k^T R_r Delta u_kright)\n        textsubject to textcolorblackx_k+1 = F x_k + G u_k quad k=0dots N-1\n         textcolorblackx_0 = hatx \n         textcolorblackunderlineb leq A_x x_k + A_u u_k  leq overlineb quad k=0 dots N-1\nendaligned","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"Consider now the specific case when we have a given dynamical system x_k+1 = F x_k + G u_k with","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"F triangleq beginbmatrix\n1  05  \n0  1\nendbmatrixquad\nG triangleq beginbmatrix\n0   \n1\nendbmatrix","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"The quantities that we want to control are y_1 = x_1, and y_2 = x_1+x_2, which can be put on the form y = C x with","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"C triangleq  beginbmatrix\n1  0    \n1  1\nendbmatrix","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"and the weights of the objective are","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"Q triangleq  beginbmatrix\n1  0    \n0  1\nendbmatrixquad\nR = 0 quad\nRr= 1","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"Moreover, we assume that we have the input constraint -3 leq u leq 3, and the output constraints  0 leq y_1 leq 1, and 0 leq y_2 leq 2. Finally, we have the constraint -1 leq 2 x_1 - x_2 leq 2.","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"We can create an MPC controller for the corresponding problem with the following code: ","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"using LinearMPC\n\n# dynamics\nF = [1 0.5; 0 1]\nG = [0;1]\n\n# create mpc struct\nmpc  = LinearMPC.MPC(F,G; C=[1 0; 1  1])\n\n# objective\nset_objective!(mpc, Q=[1,1], R=0, Rr = [1])\n\n# add constraints\nset_bounds!(mpc,umin=[-3],umax=[3], ymin= [0, 0],ymax = [1,2])\nadd_constraint!(mpc,Ax = [2 -1], lb = [-1], ub = [2])\n\n# the prediction/control horizons\nset_horizon!(mpc, Np=10)","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"where the last command set_horizon!(Np=10) sets the prediction horizon of the controller to 10 time steps.","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"That is it! Let's try our MPC controller.","category":"page"},{"location":"manual/simple/#Testing-the-MPC-controller-in-simulation","page":"Simple example","title":"Testing the MPC controller in simulation","text":"","category":"section"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"The function compute_control(mpc,x;r) uses the MPC controller mpc to compute an optimal control action given the state x and reference value r. For example,","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"u = compute_control(mpc,[0.5,1];r=[0,0])","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"gives that the optimal control action at x=[0.5,1] with r=[0,0] is u=-1.","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"Still, it is hard to draw any conclusion about wheter the controller is doing what we desire based on solving just one problem. To give a better feel of the performance of the MPC, we can create a Simulation for it. The following code simulates the closed-loop system, starting at x0=[0,0], with a reference value r=[1,0], for N=10 time steps:","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"# simulate the system\nsim = LinearMPC.Simulation(mpc;x0=[0,0],r=[1,0],N=10)\n","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"To visualize the result we can use the plotting package Plots:","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"using Plots\nplot(sim)\n","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"<p><img src=\"../../assets/simple_sim1.svg\" alt=\"simple_sim1\" width=700 style=\"background-color:white; \n    border:20px solid white; display: block; margin-left: auto; margin-right: auto;\"/></p>","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"We can see that both of the output are not following the references very well. This is due to the  desired value r=[1,0] not satisfying the constraints, which makes it impossible to reach it. If we, however, mainly want  y_1 to reach its reference, we can increase the weight of y_1 from 1 to 1000: ","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"set_objective!(mpc, Q=[1000, 1], Rr = [1])\nsim = LinearMPC.Simulation(mpc;x0=[0,0],r=[1,0],N=10)\nplot(sim)","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"<p><img src=\"../../assets/simple_sim2.svg\" alt=\"simple_sim2\" width=700 style=\"background-color:white; \n    border:20px solid white; display: block; margin-left: auto; margin-right: auto;\"/></p>","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"This gives the desired effect, since now y_1 is able to follow its reference. The output y_2 still don't reach its reference value of 0 due to the constraint -1leq 2 x_1 - x_2 leq 2. With the controller doing what we want, it is ready to be deployed in practice! ","category":"page"},{"location":"manual/simple/#Code-generation","page":"Simple example","title":"Code generation","text":"","category":"section"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"Most real-time controllers run on embedded hardware, which often require the controller to be implemented in a low-level programmign language like C. However, implementing an MPC controller in C from scratch is a very time consuming endeveaur. To simplify the process, LinearMPC.jl can generate C-code for MPC controllers that have been designed and tested in Julia, which enables the MPC controller to easibly be applied on embedded systems. To generate such C code in a directory code_dir, we can run the following code","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"LinearMPC.codegen(mpc; dir=\"code_dir\", fname=\"test_mpc\")","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"where fname determines some of the naming of the generated code.","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"The main function of interest (located in {fname}.h) is mpc_compute_control(control, state, reference, disturbance). This function computes the optimal control given the current state, reference, and measured disturbances disturbance, which are all floating-point arrays. The optimal control is stored in the floating-point array control.","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"To run a quick test of the generated code, let's test to compute a control for x=[0,0] and r=[1,0]. We do this with the following C-code, which we put in a file called test.c:","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"#include \"test_mpc.h\" \n#include <stdio.h>\nint main(){\n    // initialize \n    c_float control[1] = {0};\n    c_float state[2] = {0,0};\n    c_float reference[2] = {1,0};\n \n    // Get the control at the current state/reference \n    mpc_compute_control(control,state,reference,NULL);\n\n    // print the computed control\n    printf(\"the control is: %f\\n\", control[0]);\n}","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"where the #include \"test_mpc.h\" comes from our selection of fname (and the inclusion of stdio is just necessary for printing in the example code.) ","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"Let's compile the code with GCC by running the following commands in a terminal: ","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"gcc *.c -o test.out","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"If we run the example with ./test.out we get the following output","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"the control is: 1.000000","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"which matches the control computed by the controller at the first time step in the second simulation above. Hence, the MPC controller seems to work as expected. ","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"How the values of state,reference, and disturbance in the generated C-code are set depends on the particular application. For example, state might come from a state observer, and reference might come from some motion planner or user interface.","category":"page"},{"location":"manual/objective/#man_objective","page":"Objective function","title":"Objective function","text":"","category":"section"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"The basic objective for computing a control action in the MPC controller is of the form ","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"textcolorblacksum_k=0^N-1 left((Cx_k-r)^T Q (C x_k-r) + u_k^T R u_k + Delta u_k^T R_r Delta u_kright)","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"where N is the prediction horizon of the controller.","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"For an MPC controller mpc, the weighting matrices Q, R, and R_r that defines the objective can be set with ","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"set_objective!(mpc;Q,R,Rr)","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"If a vector value of Q,R, or R_r are inputted to set_objective, it will be interpreted as a diagonal matrix with the vector on diagonal. Similarly, if a scalar is inputted, it will be interpreted as a diagonal matrix with this value on the diagonal.","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"The default values are Q=I, R=I, and R_r = 0.","category":"page"},{"location":"manual/objective/#Reference-tracking","page":"Objective function","title":"Reference tracking","text":"","category":"section"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"The first term (Cx_k-r)^T Q (C x_k-r) is for reference tracking, which means that it aims to make Cx = r, where the matrix C is set by the user when initializing the model. Typically, the weighting matrix Q is a diagonal matrix, where higher weights are selected for the rows of C x that should be prioritized.","category":"page"},{"location":"manual/objective/#Control-energy","page":"Objective function","title":"Control energy","text":"","category":"section"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"The second term u_k^T R u_k penalizes larger values of the control action. Typically, the weighting matrix R is a diagonal matrix, where higher weights are selected for the control signals that are more \"expensive\".","category":"page"},{"location":"manual/objective/#Control-change","page":"Objective function","title":"Control change","text":"","category":"section"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"The third term Delta u_k^T R Delta u_k penalizes changes to the control action. Typically, the weighting matrix R_r is a diagonal matrix, where higher weights are selected for the control signals that are more \"expensive\".","category":"page"},{"location":"manual/objective/#Terminal-constraint","page":"Objective function","title":"Terminal constraint","text":"","category":"section"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"A term of the form (Cx_N-r)^T Q_f (C x_N -r)^T can also be added to the objective. This adds an additional terminal cost, which can be useful to ensure stability[Mayne00]. The terminal weight Q_f is set with set_objective!, and is by default the same as Q. ","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"[Mayne00]: Mayne, David Q., et al. \"Constrained model predictive control: Stability and optimality.\" Automatica 36.6 (2000): 789-814.","category":"page"},{"location":"manual/objective/#Cross-term","page":"Objective function","title":"Cross term","text":"","category":"section"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"It is also possible to include a cross term x_k^T S u_k in the objective. This term can also be set with the set_objective! function. By default, S=0.","category":"page"},{"location":"manual/constraints/#man_constraints","page":"Constraints","title":"Constraints","text":"","category":"section"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"The constraints that are supported in LinearMPC.jl are of the form ","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"underlineb leq A_x x_k + A_u u_k leq overlineb","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"Such constraints can be added with the function add_constraint!.","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"Bounds on controls (underlineu leq u leq overlineu) and on outputs (underliney leq y leq overliney) can be set in a special way with the function set_bounds!.","category":"page"},{"location":"manual/constraints/#Illustrative-example","page":"Constraints","title":"Illustrative example","text":"","category":"section"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"As an illustrative example, consider the case with two controls u_1 and u_2, two outputs y_1 and y_2, and three states x_1, x_2, and x_3, where we want to impose the following constraints","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"beginaligned\n-2 leq u_1 leq 1  \n0 leq u_2 leq 3 \n-1 leq y_1 leq 1  \n-3 leq y_2 leq 0 \n-1 leq x_2 - 3 x_3 leq 5 \n-1 leq x_1 - 2 x_2 + u_2 leq 1\nendaligned","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"This can be added to an MPC controller mpc with the following commands","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"# control + output bounds\nset_bounds!(mpc;umin=[-2,0], umax = [1,3], ymin = [-1,-3], ymax = [1,0])\n\n# -1 ≤ x2 - 3 x3 ≤  5 \nadd_constraint!(mpc; Ax = [1 0 3], lb = -2, ub = 5)\n\n# -1 ≤ x1 - 2 x2 + u2 ≤  1\nadd_constraint!(mpc; Ax = [1 -2 0], Au = [0 1], lb = -1, ub = 1)","category":"page"},{"location":"manual/constraints/#Constraint-horizon","page":"Constraints","title":"Constraint horizon","text":"","category":"section"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"The constraints from above will be enforced for all time steps up until the prediction horizon. It is, however, possible to specify a limited subset of time steps when a constraint should be satisfied. In other words, constraints are of the form","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"underlineb leq A_x x_k + A_u u_k leq overlinebqquad  textfor all  kin mathcalK","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"where the index set mathcalK subseteq 1dotsN_p determines for which time steps the constraint should be enforced. By default mathcalK = 1dots N_p. The indices for which the constraints should be enforced are specified with the optional argument ks to add_constraint!.  ","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"For example, say that we want to add the constraint","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"-1 leq x_1 + x_2 + 3 x_3 leq 1 qquad k in 246","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"to the MPC controller mpc. This can be done with ","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"add_constraint!(mpc;Ax=[1 1 3], lb = -1, ub = 1, ks = [2,4,6])","category":"page"},{"location":"manual/constraints/#Soft-constraints","page":"Constraints","title":"Soft constraints","text":"","category":"section"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"To ensure that there is a solution to the resulting optimization problem, it can be good to soften some constraint. A soft constraints means that the constraints is allowed to be violated, but such violations are penalized. A constraint can be marked to be soft by setting the optional argument soft to true. For example, if the constraint from above should be soft, one could run the command ","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"add_constraint!(mpc;Ax=[1 1 3], lb = -1, ub = 1, ks = [2,4,6], soft=true)","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"By default, bound constraints on inputs u are hard, and bound constraint outputs y are soft.","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"To be more specific, a constraint underlineb leq A_x x_k + A_u u_k leq overlineb is softened by introducing a slack variable epsilon, and replace the constraint with the constraints ","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"beginaligned\nunderlineb-epsilon leq A_x x_k + A_u u_k  \n A_x x_k + A_u u_k leq overlineb + epsilon\nendaligned","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"To penalize violation of the constraint, a term rho epsilon is added to the objective function, where the weight rho determines how hard the soft constraints should be penalized. By default, rho is set to 1e6. ","category":"page"},{"location":"manual/prestab/#man_prestabl","page":"Prestabilization","title":"Prestabilization","text":"","category":"section"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"The optimization problem that is solved is obtained by simulating the system forward using the dynamics","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"x_k+1 = F x_k + G u_k","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"This might lead to an ill-conditioned optimization problem if F is unstable and the prediction horizon is long. To mitigate numerical problems, one can use a prestabilizing feedback, which reparametrizes u with a new decision variable v and a feedback gain K as","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"u_k = -K x_k +v_k","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"This gives the new closed-loop system","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"x_k+1 = (F-GK) x_k + G v_k","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"If K is selected such that F-GK is stable, the condensed Quadratic program will be better conditioned compared to the unstable F.","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"In LinearMPC.jl you can set a stabilizing feedback K for an MPC controller mpc with","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"set_stabilizing_feedback!(mpc,K)","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"A popular choice of K is as the gain from solving an infinite horizon LQR problem. This gain can be set as the stabilizing feedback with","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"set_stabilizing_feedback!(mpc)","category":"page"},{"location":"manual/prestab/#Example","page":"Prestabilization","title":"Example","text":"","category":"section"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"Consider a first-order system with a pole in 10, which has the transfer function  ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"G(s) = frac10s-10","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"Let's create an MPC controller with prediction horizon N_p = 50 and sample time T_s = 01 seconds for this system:","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"using LinearMPC\nusing ControlSystemsBase\n\nsys = tf([1],[1, -10])\nmpc = LinearMPC.MPC(sys;Np=50, Ts=0.1)\nset_objective!(mpc;Q=1,Rr=1,R=0)","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"Moreover, we set the weights Q = 1 and R_r = 1 to be able to track references.","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"If we try to simulate the system with this controller for N=100 time steps with the setpoint r=1 ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"sim = LinearMPC.Simulation(mpc;r=[1],N=100)","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"we get an error telling us \"Could not setup optimization problem\". The reason for this error is that the resulting optimization problem is very ill-conditioned, and cannot handled by the optimization solver. ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"To see this more closley, we can check the condition number for the Hessian of the resulting optimization problem: ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"using LinearAlgebra\noptimization_problem = LinearMPC.mpc2mpqp(mpc)\ndisplay(cond(optimization_problem.H))","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"which is around 1e43. This is a very ill-conditioned problem (typically condition numbers above approx 1e6 might lead to numerical problems.) ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"To make the optimization problems better conditioned, we can add a prestabilizing feedback: ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"set_prestabilizing_feedback!(mpc)","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"Now if we check the condition number again ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"optimization_problem = LinearMPC.mpc2mpqp(mpc)\ndisplay(cond(optimization_problem.H))\n","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"we get that it is approx 8e2, which is a striking improvement! Now, if we simulate the system again, but with our updated controller, we get that the output sucessfully tracks the reference r=1. ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"sim = LinearMPC.Simulation(mpc;r=[1],N=100)\nusing Plots\nplot(sim)","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"<p><img src=\"../../assets/step_prestab.svg\" alt=\"simple_sim1\" width=700 style=\"background-color:white; \n    border:20px solid white; display: block; margin-left: auto; margin-right: auto;\"/></p>","category":"page"},{"location":"#LinearMPC.jl","page":"Home","title":"LinearMPC.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"note: Documentation under development\nThe documentation for LineaerMPC.jl is currently under development","category":"page"},{"location":"","page":"Home","title":"Home","text":"The focus of LinearMPC.jl is Model Predictive Control (MPC) of linear systems. The aim of the package is to produce high-performant and lightweight C-code that can easily be used on embedded systems, while at the same time give a user-friendly and expressive development environment for MPC. The package supports code generation for the Quadratic Programming solver DAQP, and for explicit solutions computed by ParametricDAQP.jl.","category":"page"},{"location":"#Model-Predictive-Control","page":"Home","title":"Model Predictive Control","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In MPC, an optimal control decision is computed at every sampling instance by solving an optimization probelm. On a high-level, the optimization problems solved are of the form","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginaligned\n        undersetu_0dotsu_N-1textminimize textcolorpurplefrac12sum_k=0^N-1 left((Cx_k-r)^T Q (C x_k-r) + u_k^T R u_k + Delta u_k^T R_r Delta u_kright)\n        textsubject to textcolorbluex_k+1 = F x_k + G u_k quad k=0dots N-1\n         textcolorredx_0 = hatx \n         textcolorgreenunderlineb leq A_x x_k + A_u u_k  leq overlineb quad k=0 dots N-1\nendaligned","category":"page"},{"location":"","page":"Home","title":"Home","text":"where an textcolorpurpletextobjective is minimized , subject to a textcolorbluetextdynamical system that is simulated over a horizon N, textcolorredtextstarting from an estimate hatx of the current state. Additionally, textcolorgreentextconstraints like actuator limits and state constraints are accounted for. The objective is comprised by the deviation of an output y= Cx from a reference value r, the control effort (u^T R u) , and the change of the control action Delta u^T R_r Delta u. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"LinearMPC.jl generates a condensed problem by eliminating the equality constraint. The resuliting optimization problem is a dense Quadratic Program (QP). LinearMPC.jl uses the QP sovler DAQP, a dual active-set solver that has been specialized to solved such problems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The solution map for the optimization problem is a piecewise affine function over polyhedral regions. LinearMPC.jl supports the computation of such explicit solutions by interfacing the multi-parameteric QP solver ParametricDAQP.jl","category":"page"},{"location":"#Why-LinearMPC.jl?","page":"Home","title":"Why LinearMPC.jl?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Code generation of high-performant, allocation-free, library-free, and lightweight C-code that can be embedded on any micro controller. \nState-of-the-art computation of explicit solutions (~100x faster than other software packages)  \nTools to determine real-time certificates of the complexity of the solver, allowing for MPC in with guarantees on the memory and computational requirements before deploying the solver.","category":"page"},{"location":"#Why-not-LinearMPC.jl?","page":"Home","title":"Why not LinearMPC.jl?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"As its name suggests, the package is specialized for MPC for linear systems. If a linear (or linearized) model does not suffices for your use case, consider the following packages.","category":"page"},{"location":"","page":"Home","title":"Home","text":"ModelPredictiveControl.jl - A high-level MPC packages in Julia. While it does not generate embeddable C-code, it is an excellent package during development of MPC controllers. \nacados - provides fast and embedded solvers for nonlinear optimal control, specifically designed for real-time applications and embedded systems. This is the current state-of-the art if you are interested in real-time nonlinear MPC on embedded systems. \nAre you more of a Python person? You can still use LinearMPC.jl through its sister package lmpc.","category":"page"}]
}
