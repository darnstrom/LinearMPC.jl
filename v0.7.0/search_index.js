var documenterSearchIndex = {"docs":
[{"location":"manual/reference_preview/#Reference-Preview","page":"Reference Preview","title":"Reference Preview","text":"","category":"section"},{"location":"manual/reference_preview/","page":"Reference Preview","title":"Reference Preview","text":"Reference preview allows the MPC controller to use knowledge of future reference values, enabling better tracking performance for time-varying setpoints.","category":"page"},{"location":"manual/reference_preview/#Setup","page":"Reference Preview","title":"Setup","text":"","category":"section"},{"location":"manual/reference_preview/","page":"Reference Preview","title":"Reference Preview","text":"Enable reference preview in the MPC settings:","category":"page"},{"location":"manual/reference_preview/","page":"Reference Preview","title":"Reference Preview","text":"mpc.settings.reference_preview = true\nsetup!(mpc)  # Rebuild the controller with new settings","category":"page"},{"location":"manual/reference_preview/#Usage","page":"Reference Preview","title":"Usage","text":"","category":"section"},{"location":"manual/reference_preview/#Reference-Format","page":"Reference Preview","title":"Reference Format","text":"","category":"section"},{"location":"manual/reference_preview/","page":"Reference Preview","title":"Reference Preview","text":"Provide references as a matrix of size (ny, Np) where:","category":"page"},{"location":"manual/reference_preview/","page":"Reference Preview","title":"Reference Preview","text":"ny is the number of outputs\nNp is the prediction horizon","category":"page"},{"location":"manual/reference_preview/","page":"Reference Preview","title":"Reference Preview","text":"# For a system with 2 outputs and prediction horizon of 5\nr_trajectory = [1.0 1.5 2.0 2.0 2.0;   # Reference for output 1\n                0.0 0.0 0.5 1.0 1.0]   # Reference for output 2\n\nu = compute_control(mpc, x; r=r_trajectory)","category":"page"},{"location":"manual/reference_preview/#Single-Reference","page":"Reference Preview","title":"Single Reference","text":"","category":"section"},{"location":"manual/reference_preview/","page":"Reference Preview","title":"Reference Preview","text":"Vector inputs are automatically broadcast across the prediction horizon:","category":"page"},{"location":"manual/reference_preview/","page":"Reference Preview","title":"Reference Preview","text":"# This reference will be used for all time steps\nu = compute_control(mpc, x; r=[1.0, 0.0])","category":"page"},{"location":"manual/reference_preview/#Example","page":"Reference Preview","title":"Example","text":"","category":"section"},{"location":"manual/reference_preview/","page":"Reference Preview","title":"Reference Preview","text":"using LinearMPC\n\n# Create MPC with reference preview\nA = [1 1; 0 1]\nB = [0; 1] \nC = [1.0 0; 0 1.0]\nmpc = LinearMPC.MPC(A, B; C, Np=10, Nc=5)\nset_objective!(mpc; Q=[1.0, 1.0], R=[0.1])\n\n# Enable reference preview\nmpc.settings.reference_preview = true\nsetup!(mpc)\n\n# Define reference trajectory (2 outputs × 10 time steps)\nr_traj = [zeros(1,5) ones(1,5);      # Step change for output 1\n          zeros(1,10)]               # Zero reference for output 2\n\n# Compute control with preview\nx = randn(2)\nu = compute_control(mpc, x; r=r_traj)\nnothing # hide","category":"page"},{"location":"manual/reference_preview/#Simulation","page":"Reference Preview","title":"Simulation","text":"","category":"section"},{"location":"manual/reference_preview/","page":"Reference Preview","title":"Reference Preview","text":"The Simulation function automatically handles reference preview when enabled:","category":"page"},{"location":"manual/reference_preview/","page":"Reference Preview","title":"Reference Preview","text":"# Reference trajectory for simulation\nN_sim = 30\nr_sim = zeros(2, N_sim)\nr_sim[1, 15:end] .= 1.0  # Step reference at time 20\n\nsim = Simulation(mpc; x0=zeros(2), N=N_sim, r=r_sim)\nnothing # hide","category":"page"},{"location":"manual/reference_preview/","page":"Reference Preview","title":"Reference Preview","text":"using Plots\nplot(sim)","category":"page"},{"location":"manual/reference_preview/","page":"Reference Preview","title":"Reference Preview","text":"Notice how the controller initiates the move from 0 to 1 already before the reference actually changes. If you look really closely, you can see that the output actually initially goes down rather than up before the reference change occurs, this is a phenomenon arising due to the quadratic cost function which makes it worthwhile to allow a small (\"small squared\" is really small) deviation in order to build up momentum in advance of the large reference change in order to reduce the large error (\"large squared\" is really large) arising from the step much faster.","category":"page"},{"location":"manual/reference_preview/#Code-Generation","page":"Reference Preview","title":"Code Generation","text":"","category":"section"},{"location":"manual/reference_preview/","page":"Reference Preview","title":"Reference Preview","text":"Reference preview is supported in generated C code. The generated mpc_compute_control function expects a reference array of size ny * Np when preview is enabled.","category":"page"},{"location":"manual/codegen/#man_codegen","page":"Code Generation","title":"Code Generation","text":"","category":"section"},{"location":"manual/codegen/","page":"Code Generation","title":"Code Generation","text":"Allocation free\nShow basic file structure, \nHow to call code ","category":"page"},{"location":"functions/#Functions","page":"Functions","title":"Functions","text":"","category":"section"},{"location":"functions/#LinearMPC.MPCSettings","page":"Functions","title":"LinearMPC.MPCSettings","text":"MPC controller settings.\n\nFields\n\nreference_condensation::Bool = false: Collapse reference trajectory to setpoint \nreference_tracking::Bool = true: Enable reference tracking\nreference_preview::Bool = false: Enable time-varying reference preview\nsoft_weight::Float64 = 1e6: Penalty weight for soft constraint violations\nsolver_opts::Dict{Symbol,Any}: Additional solver options\n\n\n\n\n\n","category":"type"},{"location":"functions/#LinearMPC.add_constraint!-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.add_constraint!","text":"add_constraint!(mpc::MPC;\n    Ax, Au, Ar, Aw, Ad, Aup,\n    ub, lb, ks, soft, binary, prio)\nadd_constraint!(mpc;Ax,Au,ub,lb,\n                ks, soft, binary,prio)\n\nAdds the constraints lb ≤ Ax xₖ + Au uₖ ≤ ub for the time steps k ∈ ks (additional terms Ar rₖ, Aw wₖ, Ad dₖ, Aup u⁻ₖ are possible)\n\nsoft marks if the constraint should be softened (default false)\nbinary marks if either the upper or lower bounds should be enforced with equality (default false)\nprio marks the relative priority of the constraint (default 0)\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.certify-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.certify","text":"certify(mpc; range, AS0, opts)\n\nProvide certificates on the iteration complexity of DAQP for solving the resulting optimization problems. \n\nrange is the parameter range over which the certification should be done\nAS0 is the starting working set in DAQP (defaults to empty)\nsettings the settings used in the certification (see ASCertain.CertSettings()) \n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.compute_control-Tuple{LinearMPC.MPC, Any}","page":"Functions","title":"LinearMPC.compute_control","text":"compute_control(mpc,x;r,uprev)\n\nFor a given MPC mpc and state x, compute the optimal control action. \n\nOptional arguments: \n\nr - reference value. Can be:\nVector of length ny for constant reference\nMatrix of size (ny, Np) for reference preview (when mpc.settings.reference_preview = true)\nuprev - previous control action\n\nAll arguments default to zero.\n\nExamples\n\n# Standard reference tracking\nu = compute_control(mpc, x; r=[1.0, 0.0])\n\n# Reference preview (requires mpc.settings.reference_preview = true)\nr_trajectory = [1.0 1.5 2.0 2.0 2.0;   # ny × Np matrix\n                0.0 0.0 0.5 1.0 1.0]\nu = compute_control(mpc, x; r=r_trajectory)\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.condense_reference-Tuple{Union{ExplicitMPC, LinearMPC.MPC}, Any}","page":"Functions","title":"LinearMPC.condense_reference","text":"condense_reference(mpc, r)\n\nCondense reference trajectory to single setpoint.\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.constraint_violation-Tuple{LinearMPC.Constraint, Vector{Float64}, Vector{Float64}}","page":"Functions","title":"LinearMPC.constraint_violation","text":"constraint_violation(c,xs,us)\n\nevaluates the possible violation of constraint c at state x and control u\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.correct_state!-Tuple{Union{ExplicitMPC, LinearMPC.MPC}, Any}","page":"Functions","title":"LinearMPC.correct_state!","text":"set_correct_state!(mpcy)\n\nCorrect the state estimated based on measurement u. This updates the state of state_observer\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.evaluate_cost","page":"Functions","title":"LinearMPC.evaluate_cost","text":"evaluate_cost(mpc,xs,us,rs;Q,Rr,S)\n\nCompute the cost 0.5 ∑ x'*Q x + u' R u + Δu' Rr Δu + x' S u\n\n\n\n\n\n","category":"function"},{"location":"functions/#LinearMPC.evaluate_cost-Tuple{LinearMPC.MPC, Simulation}","page":"Functions","title":"LinearMPC.evaluate_cost","text":"evaluate_cost(mpc,sim;Q,Rr,S)\n\nCompute the cost 0.5 ∑ x'*Q x + u' R u + Δu' Rr Δu + x' S u\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.format_reference-Tuple{Union{ExplicitMPC, LinearMPC.MPC}, Any}","page":"Functions","title":"LinearMPC.format_reference","text":"format_reference(mpc, r)\n\nFormat reference input for MPC controller. Handles both single reference  and reference preview scenarios.\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.get_reference_preview-Tuple{Any, Any, Any}","page":"Functions","title":"LinearMPC.get_reference_preview","text":"get_reference_preview(rs, k, Np)\n\nExtract reference preview from reference trajectory starting at time step k.\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.get_state-Tuple{Union{ExplicitMPC, LinearMPC.MPC}}","page":"Functions","title":"LinearMPC.get_state","text":"get_state!(mpc)\n\nGet the current state of the observer\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.move_block!-Tuple{Any, Any}","page":"Functions","title":"LinearMPC.move_block!","text":"move_block!(mpc,block)\n\nReduce the number of controls by keeping it constant in blocks. For example, block=[2,1,3] keeps the control constant for 2 time-steps, 1 time step, and 3 time steps.\n\nif sum(block) ≠ mpc.Np, the resulting block will be padded or clipped\nif block is an Int, a vector with constant block size is created\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.mpc2mpqp-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.mpc2mpqp","text":"mpc2mpqp(mpc)\n\nFor a given MPC structure mpc, form the multi-parametric QP mpQP. \n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.predict_state!-Tuple{Union{ExplicitMPC, LinearMPC.MPC}, Any}","page":"Functions","title":"LinearMPC.predict_state!","text":"predict_state!(mpc,u)\n\nPredict the state at the next time step if the control u is applied. This updates the state of state_observer\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_binary_controls!-Tuple{Any, Any}","page":"Functions","title":"LinearMPC.set_binary_controls!","text":"set_binary_controls!(mpc,bin_ids)\n\nMakes the controls in bin_ids to binary controls \n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_bounds!-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.set_bounds!","text":"set_bounds!(mpc;umin,umax,ymin,umax)\n\nSets the bounds umin ≤ u ≤ umax and ymin ≤ y ≤ umax\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_disturbance!-Tuple{Any, Any, Any}","page":"Functions","title":"LinearMPC.set_disturbance!","text":"set_disturbance!(mpc,wmin,wmax)\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_horizon!","page":"Functions","title":"LinearMPC.set_horizon!","text":"set_horizon!(mpc,Np)\n\nSets the prediction horizon Np\n\n\n\n\n\n","category":"function"},{"location":"functions/#LinearMPC.set_input_bounds!-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.set_input_bounds!","text":"set_input_bounds!(mpc;umin,umax)\n\nSets the input bounds umin ≤ u ≤ umax \n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_labels!-Tuple{Any}","page":"Functions","title":"LinearMPC.set_labels!","text":"set_labels!(mpc;x,u,y,d)\n\nSets the name of the states x, controls u, output u, disturbance d \n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_objective!-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.set_objective!","text":"set_objective!(mpc;Q,R,Rr,S,Qf)\n\nSet the weights in the objective function `xN' C' Qf C xN^T + ∑ (C xₖ - rₖ)' Q (C xₖ - rₖ)  + uₖ' R uₖ + Δuₖ' Rr Δuₖ + xₖ' S uₖ\n\nA vector is interpreted as a diagonal matrix.\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_output_bounds!-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.set_output_bounds!","text":"set_output_bounds!(mpc;ymin,ymax,\n                ks, soft, binary,prio)\n\nAdds the constraints lb ≤ C x  ≤ ub for the time steps k ∈ ks \n\nsoft marks if the constraint should be softened (default false)\nbinary marks if either the upper or lower bounds should be enforced with equality (default false)\nprio marks the relative priority of the constraint (default 0)\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_prestabilizing_feedback!-Tuple{Any, AbstractMatrix}","page":"Functions","title":"LinearMPC.set_prestabilizing_feedback!","text":"set_prestabilizing_feedback!(mpc,K)\n\nSets the prestabilizing feedback K\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_prestabilizing_feedback!-Tuple{Any}","page":"Functions","title":"LinearMPC.set_prestabilizing_feedback!","text":"set_prestabilizing_feedback!(mpc)\n\nSets the prestabilizing feedback K to the infinte horizon LQR gain`\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_state!-Tuple{Union{ExplicitMPC, LinearMPC.MPC}, Any}","page":"Functions","title":"LinearMPC.set_state!","text":"set_state!(mpc,x)\n\nSet the state of state_observer to x  \n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_state_observer!-Tuple{Union{ExplicitMPC, LinearMPC.MPC}}","page":"Functions","title":"LinearMPC.set_state_observer!","text":"set_state_observer!(mpc;F,G,C,Q,R,x0)\n\nCreates a steady-state Kalman filter for estimating the sate. If F,G, and C are not provided, the model used in mpc is used in the filter\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.set_terminal_cost!-Tuple{Any}","page":"Functions","title":"LinearMPC.set_terminal_cost!","text":"set_terminal_cost!(mpc)\n\nSets the terminal cost Qf to the inifinite horizon LQR cost \n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.settings!-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.settings!","text":"settings!(mpc,key1=value1, key2=value2,...)\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.setup!-Tuple{LinearMPC.MPC}","page":"Functions","title":"LinearMPC.setup!","text":"setup!(mpc)\n\nSets up the mpc given its current parameters and settings   Internally, this means generating an mpQP, and setting up a DAQP workspace.\n\n\n\n\n\n","category":"method"},{"location":"functions/#LinearMPC.solve-Tuple{LinearMPC.MPC, Any}","page":"Functions","title":"LinearMPC.solve","text":"xdaqp,fval,exitflag,info = solve(mpc,θ)\n\nSolve corresponding QP given the parameter θ\n\n\n\n\n\n","category":"method"},{"location":"manual/explicit/#man_empc","page":"Explict MPC","title":"Explicit MPC","text":"","category":"section"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"The resulting control law from MPC is given implicitly in terms of a solution to an optimization problem. The solution to this optimization problem does, however, have a closed-form expression when the system to be controlled is linear and time-invariant system, and the constraints are polyhedral. More concretely, the control law is piecewise affine over polyhedral regions[Bemporad02]; that is, the optimal control action u^* is a pieacwise affine function of a parameter theta, where theta contains the state, set points, measurable disturbances, and previous control actions. Explicitly the optimal control action is of the form","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"u^*(theta) = K_i theta + k_iquad text if  theta in Theta_i triangleq theta  A^theta_i theta leq b^theta_i","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"where the feedback gain K_i and offset k_i are defined for each critical region Theta_i, which is defined by the matrix A^theta_i and offset b^theta_i.","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"[Bemporad02]: Bemporad, Alberto, et al. \"The explicit linear quadratic regulator for constrained systems.\" Automatica 38.1 (2002): 3-20.","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"In explicit MPC these feedbacks and regions are stored to be used online to find an optimal control action in a two step procedure:","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"Find the index j for which theta in Theta_j\nApply the control action u = K_j theta + k_j","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"If step 1 is done correctly, this can save a lot of computations, since an optimization solver does not have to be embedded. A drawback is, however, that the number of regions grows rapidly as the problem dimension increase, resulting in a significant memory footprint (since all feedbacks + regions needs to be stored in memory.)","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"Computing the explicit solution can be quite challenging in its own right. LinearMPC.jl make use of the state-of-the-art multi-parametric programming solver ParametricDAQP.jl[Arnstrom24]","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"[Arnstrom24]: Arnström, Daniel, and Axehill, Daniel \"A High-Performant Multi-Parametric Quadratic Programming Solver,\" 2024 IEEE 63rd Conference on Decision and Control (CDC), Milan, Italy, 2024, pp. 303-308","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"For a given MPC controller mpc, an explicit MPC controller can be created with ","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"empc = LinearMPC.ExplicitMPC(mpc)","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"The resulting critical regions can be found with empc.solution.CRs, where the field Ath and bth in a critical region define the region itself, and the field z gives the feedback. Specifically, K  = z[1:end-1,:]' and k=z[end,:]', so the optimal control u can be computed for the parameter θ with u=z'*[θ;1]. ","category":"page"},{"location":"manual/explicit/#Parameter-range","page":"Explict MPC","title":"Parameter range","text":"","category":"section"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"Running the code above gives the warning \"No paramter range defined\". This is because we have not specified where in parameter space the solution should be computed. By default, a box with limits -100100 is used, but this might be too big or too small of a volume. Instead, users can provide a ParameterRange which defines where in parameter space the solution should be computed. For example  ","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"parameter_range = LinearMPC.ParameterRange(mpc)\nparameter_range.xmin[:] .= -1\nparameter_range.xmax[:] .=  1","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"will consider states in the unit box. Similarly, one can modify the range for ","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"references by modifying the field rmin and rmax\ndisturbances by modifying the field dmin and dmax","category":"page"},{"location":"manual/explicit/#Computing-control","page":"Explict MPC","title":"Computing control","text":"","category":"section"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"To efficiently compute a control action using explicit MPC controller, LinearMPC.jl constructs a  binary search tree[Tondel03]. This can be done with","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"LinearMPC.build_tree!(empc)","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"[Tondel03]: Tøndel, Petter, Tor Arne Johansen, and Alberto Bemporad. \"Evaluation of piecewise affine control via binary search tree.\" Automatica 39.5 (2003): 945-950.","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"A binary search tree will also be compuetd by passing the optional argument buil_tree to EMPC:  ","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"empc = LinearMPC.ExplicitMPC(mpc;build_tree=true)","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"When a binary search tree has been formed , a control can be computed, similar as for a normal MPC struct, with the function compute_control. Given a state x and setpoint r, the corresponding control is computed with ","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"x = LinearMPC.compute_control(empc,x;r=r)","category":"page"},{"location":"manual/explicit/#Code-generation","page":"Explict MPC","title":"Code generation","text":"","category":"section"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"C code for an explicit MPC controller can be generate with codegen. The call","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"LinearMPC.codegen(empc;dir=\"code_dir\")","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"will generate C code in the directory code_dir.","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"The main function of interest is mpc_compute_control(control, state, reference, disturbance). This function computes the optimal control given the current state, reference, and measured disturbances disturbance, which are all floating-point arrays. The optimal control is stored in the floating-point array control.","category":"page"},{"location":"manual/explicit/#Example","page":"Explict MPC","title":"Example","text":"","category":"section"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"To show some of the functionality, we consider he explicit MPC controller for control a DC servo motor, also considered as an example in the MATLAB MPC Toolbox here. ","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"This is an example that is available in mpc_examples, so a template for the MPC controller can be created with","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"using LinearMPC\nmpc,para_range= LinearMPC.mpc_examples(\"dcmotor\")","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"Note that mpc_examples also provide a template for the parameter range. We do, however, want to ensure that the exlicit MPC controller is computed for x_1 leq 03  and x_2 leq 2, which we can ensure with","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"para_range.xmin[1:2] = -[0.3;2.0] \npara_range.xmax[1:2] = [0.3;2.0]","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"Next, we compute an explicit controller with ","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"empc = LinearMPC.ExplicitMPC(mpc;range=para_range)","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"If we want to visualize a slice of the resulting polytopic partition, we can use the function plot_regions. This takes in the names of the parameters to be plotted as argument. We can also fix other parameter with optional arguments (which are by default fixed at 0.) If we, for example, want to plot a 2D-slice of the partition in the first and second state, when the reference is fixed at r=0500, we run   ","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"LinearMPC.plot_regions(empc,:x1,:x2,r=[0.5,0.0])","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"<p><img src=\"../../assets/exp_regions.svg\" alt=\"simple_sim1\" width=600 style=\"background-color:white; \n    border:20px solid white; display: block; margin-left: auto; margin-right: auto;\"/></p>","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"Similarly, if we want to visualize the feedback law, we can do that with plot_feedback, where one also has to enter the name of the input to plot (in this case :u1). ","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"If we, for example, want to visualize the feedback for the first input for different x_1 and x_2, when the reference is fixed at r=0500, we run   ","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"LinearMPC.plot_feedback(empc,:u1,:x1,:x2,r=[0.5,0.0])","category":"page"},{"location":"manual/explicit/","page":"Explict MPC","title":"Explict MPC","text":"<p><img src=\"../../assets/exp_feedback.svg\" alt=\"simple_sim1\" width=600 style=\"background-color:white; \n    border:20px solid white; display: block; margin-left: auto; margin-right: auto;\"/></p>","category":"page"},{"location":"examples/invpend/#ex_invpned","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"","category":"section"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"To exemplify the basics of LinearMPC.jl, we consider the classical example of controlling a inverted pendulum on a cart. The cart can be moved by applying a force u, to control the cart position p  and pendulum angle theta. The start of using MPC is to have a model of the system we want to control, and the model which is used in an MPC controller is discrete-time state-space models of the form x_k+1 = F x_k G u_k. In ref we discuss more how to use different types of models, but the end-point is always a discrete-time state-space system. For simplicity, we assume that the following state-space model is given for cart system ","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"F = ,\\quad G = ","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"where p and dotp are the position/velocity of the cart, and theta and dottheta are the angle and angular velocity of the pendulum. ","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"Our goal is to control the cart's position p and the angle of the pendulum theta. We denote the signals we want to control with y, which in our case gives y_1 = p and y_2 = theta. How the states relates to our output y can compactly be written as y = Cx, which for the cart system gives ","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"C = ","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"An additional requirement is that we don't want the control signal to be too \"jittery\". This is addressed with a penalty Delta u R_r Delta u, where Delta u denotes the change in the control input between to time steps.  The objective at a single time step, thus becomes (Cx - y)^T Q (Cx-y) + Delta u^T R Delta u.","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"In addition to the dynamics of the system, we also want to impose additional constraint when controlling the system. First, there is a limited amount of force u that can be applied. Specifically, this gives us the following bounds on the control: -2 leq u leq 2. Moreover, we also want the angle theta to not be to large, since this would our model. Therefore, we also have the constraint -02 leq theta leq 02.","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"F = ","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"Taken together, we pose the control problem as a receding horizon control problem. ","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"Control horizon / Prediction horizon (hint at move blocking)","category":"page"},{"location":"examples/invpend/","page":"Example - Inverted Pendulum on a Cart","title":"Example - Inverted Pendulum on a Cart","text":"Simulate the system","category":"page"},{"location":"examples/invpend/#Generating-C-code","page":"Example - Inverted Pendulum on a Cart","title":"Generating C-code","text":"","category":"section"},{"location":"manual/compcert/#man_compcert","page":"Complexity Certification","title":"Complexity Certification","text":"","category":"section"},{"location":"manual/compcert/","page":"Complexity Certification","title":"Complexity Certification","text":"Real-time MPC\nIdea of mapping\nHow to call certification\nInterpreting result ","category":"page"},{"location":"manual/hybrid/#man_hybridmpc","page":"Hybrid MPC","title":"Hybrid MPC","text":"","category":"section"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"LinearMPC.jl can be used to control hybrid systems, where controls and states might take both continuous and binary values.","category":"page"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"Binary controls are either equal to its upper or lower bound. For example, if the lower and upper bounds for the control i is underlineu_i and overlineu_i, making u_i binary means that u_i in underlineu_i overlineu_i rather than underlineu_i leq u_i leq overlineu_i. Controls can be made binary with the function set_binary_controls!, which is exemplified below.","category":"page"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"More generally, LinearMPC.jl allows any constraint to be defined as binary. A constraint can be enforced to be binary by settings the setting the optional argument binary to  true in the functions add_constraint!.","category":"page"},{"location":"manual/hybrid/#Illustrative-example","page":"Hybrid MPC","title":"Illustrative example","text":"","category":"section"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"As an illustrative example, we consider the control of the attitude of a satellite[Axehill04]. The actuators consist of one reaction wheel and two thrusters. The thruster takes on binary values (they are either 'on' or 'off')","category":"page"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"[Axehill04]: Axehill, Daniel, and Hansson, Anders. \"A preprocessing algorithm for MIQP solvers with applications to MPC.\" 43rd IEEE Conference on Decision and Control (CDC) (2004) ","category":"page"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"The dynamics of the system is given by","category":"page"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"dotx = beginbmatrix\n    0  1  0  0  0  0 0  0  0 \nendbmatrix x  \n+ beginbmatrix\n    0  0  0 \n    25  1  1 \n    -10  0  0\nendbmatrix\nbeginbmatrix\n u_1 \n u_2 \n u_3 \nendbmatrix","category":"page"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"where x_1 i the attitude of the satellite. ","category":"page"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"The thrusters give rise to the binary controls u_2 in 01 and u_3 in -10.","category":"page"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"An MPC controller that controls the attitude of the satellite can be set up with LinearMPC.jl as follows: ","category":"page"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"using LinearMPC\n# Setup dynamics + horizon\nA = [0.0 1 0; 0 0 0; 0 0 0]\nB = [0 0 0; 2.5 1 1; -10 0 0]\nmpc = LinearMPC.MPC(A,B,0.1;Np=20)\n\n# Setup the binary controls u_2 {0,1} and u3 in {-1,0}\nset_binary_controls!(mpc,[2,3])\nset_bounds!(mpc;umin=[-Inf;0;-1],umax=[Inf;1;0])\n\n# Setup objetive to prioritize tracking of the attitude x1\nset_objective!(mpc;Q=[0.5e4, 1e-2, 1e-1], R = [10,10,10], Rr = 0)\n\n# Enable reference preview\nmpc.settings.reference_preview = true\nnothing # hide","category":"page"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"We simulate the controller with an attitude reference change to 0.5 after 5 time steps with the following code","category":"page"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"x0, N = zeros(3), 20; \nrs = [zeros(1,5) 0.5*ones(1,N-5);\n      zeros(2,N)];\ndynamics = (x,u,d) -> mpc.model.F*x + mpc.model.G*u\nsim = LinearMPC.Simulation(dynamics, mpc; x0,N, r=rs)\nnothing # hide","category":"page"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"The result of the simulation can be plotted with ","category":"page"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"using Plots\nplot(sim)","category":"page"},{"location":"manual/hybrid/","page":"Hybrid MPC","title":"Hybrid MPC","text":"We can see that the attitude is able to reach the setpoint of 0.5. Moreover, we also we that u_2 and u_3 only take values in 01 and -10, respectively.","category":"page"},{"location":"manual/simulation/#man_simulation","page":"Simulating","title":"Simulating","text":"","category":"section"},{"location":"manual/simulation/","page":"Simulating","title":"Simulating","text":"Simulation class \nRunning simulation\nVisualizing\nCallback","category":"page"},{"location":"manual/moveblock/#man_moveblock","page":"Move blocking ","title":"Move Blocking","text":"","category":"section"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"A distinguishing characteristic of MPC compared with more classical control strategies such as PID or LQR is that it can be computationally demanding. For real-time applications, this can be a limiting factor.","category":"page"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"One way of reducing the computational complexity is to reduce the number of decision variable in the MPC. This can be done by reducing the prediction horizon, but this can reduce the performance of the controller significantly (as is shown in the example below.) ","category":"page"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"Another way is to \"block\" some of the controls by holding them constant over more than one time step, which is known as \"move blocking\"[Cagienard07]. If the blocks are selected wisely, the performance of a longer horizon may remain, while the decision variables are reduced significantly.  ","category":"page"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"[Cagienard07]: Cagienard, Raphael, et al. \"Move blocking strategies in receding horizon control.\" Journal of Process Control 17.6 (2007): 563-570.","category":"page"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"In LinearMPC.jl, controls can be blocked with the function move_block!. The function takes in a vector that defines how the control decisions should be held. For example, one can hold the control for 3 time steps, then 2 time steps, then 1 time step, then 4 time steps with","category":"page"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"move_block!(mpc,[3,2,1,4])","category":"page"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"note: Padding of move blocks\nIf the sum of the blocks add up to less than the prediction horizon, the last block will be extended to cover the entire horizon. For example, if Np = 10, the call move_block!(mpc,[2,4])  will result in the move blocks [2,8].","category":"page"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"note: Clipping of move blocks\nIf the sum of the blocks add up to more than the prediction horizon, the last blocks will be clipped until the remaining blocks add up to the prediction horizon. For example, if Np = 10, the call move_block!(mpc,[2,4,6,3]) will result in the move blocks [2,4,4].","category":"page"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"One can also enter a set of evenly spaces blocks that covers the entire horizon. For example, if Np=10, the call move_block!(mpc,2) will result in the move blocks [2,2,2,2,2].","category":"page"},{"location":"manual/moveblock/#Example","page":"Move blocking ","title":"Example","text":"","category":"section"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"Consider the example of the control of an inverted pendulum on a cart, which is predefined as one of the examples in LinearMPC.jl and can be accessed with the call mpc_examples. We consider the case when we want the first output (the position of the cart) to reach a certain value (1 m to be specific.) Below we create three different MPC controllers with different prediction horizons and show the resulting step responses.   ","category":"page"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"using LinearMPC,Plots\ntsolve, plt = zeros(3),plot();\nfor (k,Np) in  enumerate([100,75,50])\n    mpc,_ = LinearMPC.mpc_examples(\"invpend\",Np)\n    tsolve[k] = @elapsed sim = LinearMPC.Simulation(mpc;r=[1,0],N=500);\n    plot!(plt, sim,yids=[1],uids=[], color = k, label=\"Np = \"*string(Np))\nend\nplot!(plt,ylims=(-0.5,1.25))","category":"page"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"<p><img src=\"../../assets/moveblock_horizon.svg\" alt=\"simple_sim1\" width=700 style=\"background-color:white; \n    border:20px solid white; display: block; margin-left: auto; margin-right: auto;\"/></p>","category":"page"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"As can be seen, the higher the prediction horizon, the faster the setpoint is reached. (Note that for even lower values of the prediction horizon, the resulting closed-loop system becomes unstable.) The cost of the horizon can, however, be seen in the solve times, where the solve times are about four times slower for N_p = 100 compared with N_p = 50. ","category":"page"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"To reduce the computation time, we consider three different move blocks. We consider the case of no move blocks (which an empty vector of move blocks encodes,) of evenly spaced move blocks [1,1,1,1,1] and a more dynamics set of move blocks [1,1,5,10,10]. For all of the cases, we consider a prediction horizon of N_p = 100. The resulting step responses are shown below.","category":"page"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"using LinearMPC,Plots\nmpc,_ = LinearMPC.mpc_examples(\"invpend\",100)\ntsolve, plt = zeros(3),plot();\nmove_blocks = [Int[], [1,1,1,1,1], [1,1,5,10,10]]\nfor (k,mb) in  enumerate(move_blocks)\n    move_block!(mpc,mb)\n    tsolve[k] = @elapsed sim = LinearMPC.Simulation(mpc;r=[1,0],N=500);\n    plot!(plt, sim,yids=[1],uids=[], color = k, label=\"move block = \"*string(mb))\nend\nplot!(plt,ylims=(-0.5,1.25))","category":"page"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"<p><img src=\"../../assets/moveblocks.svg\" alt=\"simple_sim1\" width=700 style=\"background-color:white; \n    border:20px solid white; display: block; margin-left: auto; margin-right: auto;\"/></p>","category":"page"},{"location":"manual/moveblock/","page":"Move blocking ","title":"Move blocking ","text":"As can be seen, the adaptive move block almost performs as well as using no move blocks. The main difference is that when no move blocks are used, there are 100 decision variables, while for both the move blocks [1,1,1,1,1] and [1,1,5,10,10] there are only 5 decision variables. This can be seen in the solution times, where both of the move blocks leads to solution times that are about 6 times faster (note that the actual speedup is even higher due to some overhead from the simulation.)","category":"page"},{"location":"manual/model/#man_model","page":"Models","title":"Models","text":"","category":"section"},{"location":"manual/model/","page":"Models","title":"Models","text":"As its name suggests Model Predictive Control uses a predictive model when computing a control action. The models used internally in LinearMPC.jl are discrete-time state-space models of the form ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"x_k+1 = F x_k + G u_k","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"where the state at time step k+1 is a linear combinations of the current state x_k and a control action u_k. If matrices F and G that define such a state-space model is available, a MPC controller that uses that model is created with ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"mpc = LinearMPC.MPC(F,G)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"One can also create a Model struct first, and then create the MPC controller, with ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"model = LinearMPC.Model(F,G)\nmpc = LinearMPC.MPC(model)","category":"page"},{"location":"manual/model/#Continuous-time-models","page":"Models","title":"Continuous-time models","text":"","category":"section"},{"location":"manual/model/","page":"Models","title":"Models","text":"Often, the system dynamics is given in continuous time rather than discrete time. That is, the system dynamics is a state space model of the form ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"fracddt x(t) = A x(t) + B u(t)\n","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"One alternative to deal with this is to discretize the system, to yield matrices F and G instead of A and B. A MPC controller that use a discretized continuous-time model can be created with","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"mpc = LinearMPC.MPC(A,B,Ts)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"where Ts is the sample time, which  and determines how much one time step is. (For example, T_s = 01 corresponds to 10 time steps being 1 second.) As for discrete-time state spaces models, one can first create a Model struct, and create a MPC controller based on this model as follows: ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"model = LinearMPC.Model(A,B,Ts)\nmpc = LinearMPC.MPC(model)","category":"page"},{"location":"manual/model/#Outputs","page":"Models","title":"Outputs","text":"","category":"section"},{"location":"manual/model/","page":"Models","title":"Models","text":"In the MPC, one can make an \"output\" y of the system track a reference r. This \"output\" is a linear combination of the form  ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"y_k = C x_k ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"where C is a matrix that maps the states output. ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"note: Difference to measurements\nIn this context, y is not necessarily what is measured from the system. Instead, it should be thought of quantities that are of interest to be controlled.","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"The output of the system can be set with the  optional argument C. So for the model ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"x_k+1 = F x_k + G u_k quad y_k = C x_k","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"an MPC controller that uses this model can be created with","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"mpc = LinearMPC.MPC(F,G;C)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"or by first creating a Model as ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"model = LinearMPC.Model(F,G;C)\nmpc = LinearMPC.MPC(model)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"Similarly, an MPC controller of the continuous-time system","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"fracddt x(t) = A x(t) + B u(t) quad y(t) = C x(t)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"is setup with ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"mpc = LinearMPC.MPC(A,B,Ts;C)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"or ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"model = LinearMPC.Model(A,B,Ts;C)\nmpc = LinearMPC.MPC(model)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"note: Default value\nIf C is not provided, it is assumed that all of the states are the output (that is, y=x, or, equivalently, C=I.)","category":"page"},{"location":"manual/model/#Disturbances","page":"Models","title":"Disturbances","text":"","category":"section"},{"location":"manual/model/","page":"Models","title":"Models","text":"Models with disturbances d are also supported. Specifically, linear combinations of d is allowed to be additive to the dynamics and to the measurements as  ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"x_k+1 = F x_k + G u_k + G_d d_k quad y_k = C x_k + D_d d_k ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"where the matrices G_d and D_d determines the linear combination for the dynamics and the output, respectively. Both G_d and D_d can be set as optional arguments:","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"mpc = LinearMPC.MPC(F,G;Gd,C,Dd)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"Similarly, continuous-time state space models of the form ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"fracddt x(t) = A x(t) + B u(t) + B_d d(t) quad y(t) = C x(t) + D_d x(t)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"can be used with ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"mpc = LinearMPC.MPC(A,B,Ts;Bd,C,Dd)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"note: Constant disturbance\nThe disturbance d is assumed to be constant over the horizon ","category":"page"},{"location":"manual/model/#Linearization","page":"Models","title":"Linearization","text":"","category":"section"},{"location":"manual/model/","page":"Models","title":"Models","text":"For a nonlinear discrete-time state-space model of the form  ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"x_k+1 = f(x_ku_kd_k) quad y_k = h(x_ku_kd_k)    ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"an MPC controller with a linearized model around an operating point x_o, u_o and d_o can be created with ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"model = LinearMPC.Model(f,h,x_o,u_o; d=d_o)\nmpc = LinearMPC.MPC(model)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"Similary, for a nonlinear continuous-time state-space model of the form","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"fracddt x(t) = f(x(t)u(t)d(t)) quad y(t) = h(x(t)u(t)d(t))","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"an MPC controller with a linearized model around an operating point x_o, u_o and d_o can be created with ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"model = LinearMPC.Model(f,h,x_o,u_o,Ts; d=d_o)\nmpc = LinearMPC.MPC(model)","category":"page"},{"location":"manual/model/#Using-ControlSystems.jl","page":"Models","title":"Using ControlSystems.jl","text":"","category":"section"},{"location":"manual/model/","page":"Models","title":"Models","text":"Linear MPC also support system models from ControlSystems.jl. Specifically it supports these types of systems: ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"Transfer functions\nState-space models\nDelayed LTI systems","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"For a system sys created with ControlSystems.jl, an MPC controller can simply created with  ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"mpc = LinearMPC.MPC(sys)","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"For example, given the transfer function  ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":" G(s) = frac1s^2+2s+1 ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"and MPC controller using this transfer function as its model can be created with  ","category":"page"},{"location":"manual/model/","page":"Models","title":"Models","text":"sys = tf([1.0],[1,2,1])\nmpc = LinearMPC.MPC(sys)","category":"page"},{"location":"manual/robust/#man_robust","page":"Robust MPC","title":"Robust MPC","text":"","category":"section"},{"location":"manual/robust/","page":"Robust MPC","title":"Robust MPC","text":"Model predictive control requires a model of the system dynamics. In practice, there is often a mismatch between this model and the true dynamics. This mismatch can be captured with an additive disturbance w_k in the dynamics","category":"page"},{"location":"manual/robust/","page":"Robust MPC","title":"Robust MPC","text":"x_k+1 = F x_k + G u_k + w_k","category":"page"},{"location":"manual/robust/","page":"Robust MPC","title":"Robust MPC","text":"If the mismatch is no accounted for, constraints that are predicted to be satisfied might now be so in practice. We illustrate this with the following example of the control of a double integrator.","category":"page"},{"location":"manual/robust/","page":"Robust MPC","title":"Robust MPC","text":"using LinearMPC,Plots\n\nF,G = [1 0.1; 0 1], [0.005;0.1;;] # double integrator with Ts=0.1 \ntrue_dynamics = (x,u,d) -> F*x + G*u+0.01*(rand(2).-0.5);\n\nmpc_nominal = LinearMPC.MPC(F,G;Ts=0.1,Np=25,C=[1 0;])\nset_bounds!(mpc_nominal;umin=[-0.2],umax=[0.2],ymin=[-0.5],ymax=[0.5]) \n\nsim_nominal = Simulation(true_dynamics,mpc_nominal;r=[0.5])\nhline([0.5],label=\"Constraint bound\", linestyle=:dash)\nplot!(sim_nominal.ys[1,:],xlabel=\"Time step\", ylabel=\"Position [m]\",label=\"Nominal MPC\")\nylims!(0.4,0.6) #hide","category":"page"},{"location":"manual/robust/","page":"Robust MPC","title":"Robust MPC","text":"As the plot shows, the constraint x_1 leq 05 is violated due to the model mismatch. ","category":"page"},{"location":"manual/robust/","page":"Robust MPC","title":"Robust MPC","text":"To account for model mismatch, the function set_disturbance!(mpc,wmin,wmax) defines upper and lower bounds on the process noise, and then tightens the constraints to ensure that the original constraint is satisfied (as long as the actual disturbance w is between wmin and wmax.","category":"page"},{"location":"manual/robust/","page":"Robust MPC","title":"Robust MPC","text":"note: Tube MPC\nDoing this a priori constraint tightening is superior to many commonly used tube MPC approaches.[Zanon21].","category":"page"},{"location":"manual/robust/","page":"Robust MPC","title":"Robust MPC","text":"[Zanon21]: Zanon, Mario, and Gros, Sébastien. \"On the similarity between two popular tube MPC formulations.\" European Control Conference (ECC) (2021) ","category":"page"},{"location":"manual/robust/","page":"Robust MPC","title":"Robust MPC","text":"mpc_robust = LinearMPC.MPC(F,G;Ts=0.1,Np=25,C=[1 0;])\nset_prestabilizing_feedback!(mpc_robust)\nset_disturbance!(mpc_robust,[-0.005;-0.005],[0.005;0.005])\nset_bounds!(mpc_robust;umin=[-0.2],umax=[0.2],ymin=[-0.5],ymax=[0.5]) \n\nsim_robust = Simulation(true_dynamics,mpc_robust;r=[0.5])\nplot!(sim_robust.ys[1,:], label=\"Robust MPC\")\nylims!(0.4,0.6) #hide","category":"page"},{"location":"manual/robust/","page":"Robust MPC","title":"Robust MPC","text":"By constructing an MPC mpc_robust, we see that the constraint are satisfied despite the disturbance w. One can see that the resulting response is quite conservative. This is because the constraint are tightened to handle the worst-case noise realization. For the example and scenario in question, the worst-case disturbance is for w = left(beginsmallmatrix0005  0005 endsmallmatrixright). If we rerun the simulations for the worst-case disturbance, we get a large violation for mpc_nominal, while mpc_robust still manages to fulfill the constraints.","category":"page"},{"location":"manual/robust/","page":"Robust MPC","title":"Robust MPC","text":"worst_case_dynamics = (x,u,d) -> F*x + G*u+0.005*ones(2);\nsim_nominal_wc = Simulation(worst_case_dynamics,mpc_nominal;r=[0.5])\nsim_robust_wc = Simulation(worst_case_dynamics,mpc_robust;r=[0.5])\nhline([0.5],label=\"Constraint bound\", linestyle=:dash)\nplot!(sim_nominal_wc.ys[1,:],xlabel=\"Time step\", ylabel=\"Position [m]\",label=\"Nominal MPC\")\nplot!(sim_robust_wc.ys[1,:], label=\"Robust MPC\")\nylims!(0.4,0.6) #hide","category":"page"},{"location":"manual/robust/","page":"Robust MPC","title":"Robust MPC","text":"note: Measurable disturbance\nNote that if the disturbance w is measurable/known, it can be accounted for without having to tighten the constraints by providing it as a measurable disturbance d (see Model for details.)","category":"page"},{"location":"manual/solver/#man_solver","page":"Solver Settings","title":"Solver Settings","text":"","category":"section"},{"location":"manual/solver/","page":"Solver Settings","title":"Solver Settings","text":"Generated code\nPrecision\nTolerances\nIteration limits","category":"page"},{"location":"manual/observer/#man_observer","page":"State observer","title":"State observer","text":"","category":"section"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"Model predictive control requires all the state of the system to be known. All states are, however, rarely measured in practice. Therefore, a state observer that estimates the current states based on measurements is needed. The goal of a state observer is therefore to generate an estimate hatx of the true state x, based on measurements y and applied controls u such that hatx approx x","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"LinearMPC.jl provides a simple steady-state Kalman filter for estimating the states. The steady-state Kalman filter assumes the following model of the dynamical system","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"x_k+1 = F x_k + G u_k + w_k qquad y_k = C x_k + e_k","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"where the process noise w_k sim mathcalN(0Q) and the measurement noise e_k sim mathcalN(0R). Each time instance, the filter performs two steps: a correction step and a prediction step.  In the correction steps, the current state estimate hatx is corrected based on a measurement y according to   ","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"hatx leftarrow hatx + K(y-C hatx)","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"which corrects the state based on the deviation between the measurement y and the expected measurement Chatx. The correction step is followed by a prediction step, where the state at the next time step is predicted based on the applied control u:","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"hatx leftarrow F hatx + G u","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"For a MPC struct mpc, a steady state Kalman filter can be created with","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"set_state_observer!(mpc;Q,R)","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"where Q and R are covariance matrices for the process noise and measurement noise, respectively. These are used as tuning variables, where the relative size of the elements in Q and R determines if the prediction or the measurements should be trusted more. By default, set_state_observer! uses F, G, and C from the MPC structure. It is possible to override this by passing the optional arguments F,G,C to set_state_observer!.","category":"page"},{"location":"manual/observer/#Getting,-setting,-correcting,-and-predicting-state","page":"State observer","title":"Getting, setting, correcting, and predicting state","text":"","category":"section"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"The current state of the observer is accessed with ","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"x = get_state(mpc)","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"The state of the observer can be set to x0 with","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"set_state!(mpc,x0)","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"Given a measurement y, the state of the observer can be corrected with","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"correct_state!(mpc,y)","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"Given a control action u, the next state can be predicted with ","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"predict_state!(mpc,u)","category":"page"},{"location":"manual/observer/#Using-the-observer","page":"State observer","title":"Using the observer","text":"","category":"section"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"Typically, you want to do a correction step before computing a new control action, and then use the new control action to predict the next state. A typical sequence of calls are therefore ","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"x = correct_state!(mpc,y)\nu = compute_control(mpc,x)\npredict_state!(mpc,u)","category":"page"},{"location":"manual/observer/#Code-generation","page":"State observer","title":"Code generation","text":"","category":"section"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"If an observer has been set, the codegen function will in addition to C-code for the MPC also generate C-code for the observer. Specifically the C functions mpc_correct_state(state,measurement) and  mpc_predict_state(state,control) will be generated, where state, measurement, and control are floating-point arrays. The updated state will be available in the floating-point array state after calling the functions. ","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"Similar to the previous section, the following is a typical sequence of calls when using an observer together with mpc_compute_control ","category":"page"},{"location":"manual/observer/","page":"State observer","title":"State observer","text":"mpc_correct_state(state,measurement)\nmpc_compute_control(control,state,reference,disturbance)\nmpc_predict_state(state,control)","category":"page"},{"location":"manual/objective/#man_objective","page":"Objective function","title":"Objective function","text":"","category":"section"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"The basic objective for computing a control action in the MPC controller is of the form ","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"sum_k=0^N-1 left((Cx_k-r)^T Q (C x_k-r) + u_k^T R u_k + Delta u_k^T R_r Delta u_kright)","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"where N is the prediction horizon of the controller.","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"For an MPC controller mpc, the weighting matrices Q, R, and R_r that defines the objective can be set with ","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"set_objective!(mpc;Q,R,Rr)","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"If a vector value of Q,R, or R_r are inputted to set_objective, it will be interpreted as a diagonal matrix with the vector on diagonal. Similarly, if a scalar is inputted, it will be interpreted as a diagonal matrix with this value on the diagonal.","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"The default values are Q=I, R=I, and R_r = 0.","category":"page"},{"location":"manual/objective/#Reference-tracking","page":"Objective function","title":"Reference tracking","text":"","category":"section"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"The first term (Cx_k-r)^T Q (C x_k-r) is for reference tracking, which means that it aims to make Cx = r, where the matrix C is set by the user when initializing the model. Typically, the weighting matrix Q is a diagonal matrix, where higher weights are selected for the rows of C x that should be prioritized.","category":"page"},{"location":"manual/objective/#Control-energy","page":"Objective function","title":"Control energy","text":"","category":"section"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"The second term u_k^T R u_k penalizes larger values of the control action. Typically, the weighting matrix R is a diagonal matrix, where higher weights are selected for the control signals that are more \"expensive\".","category":"page"},{"location":"manual/objective/#Control-change","page":"Objective function","title":"Control change","text":"","category":"section"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"The third term Delta u_k^T R Delta u_k penalizes changes to the control action. Typically, the weighting matrix R_r is a diagonal matrix, where higher weights are selected for the control signals that are more \"expensive\".","category":"page"},{"location":"manual/objective/#Terminal-constraint","page":"Objective function","title":"Terminal constraint","text":"","category":"section"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"A term of the form (Cx_N-r)^T Q_f (C x_N -r)^T can also be added to the objective. This adds an additional terminal cost, which can be useful to ensure stability[Mayne00]. The terminal weight Q_f is set with set_objective!, and is by default the same as Q. ","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"[Mayne00]: Mayne, David Q., et al. \"Constrained model predictive control: Stability and optimality.\" Automatica 36.6 (2000): 789-814.","category":"page"},{"location":"manual/objective/#Cross-term","page":"Objective function","title":"Cross term","text":"","category":"section"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"It is also possible to include a cross term x_k^T S u_k in the objective. This term can also be set with the set_objective! function. By default, S=0.","category":"page"},{"location":"manual/objective/#Reference-Preview","page":"Objective function","title":"Reference Preview","text":"","category":"section"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"By default, the reference tracking term uses a constant reference r across the prediction horizon: (Cx_k-r)^T Q (C x_k-r) for all k. ","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"Reference preview allows time-varying references r_k in the objective:","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"sum_k=0^N-1 (Cx_k-r_k)^T Q (C x_k-r_k)","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"Enable reference preview with:","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"mpc.settings.reference_preview = true\nsetup!(mpc)","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"Then provide a reference trajectory matrix of size (ny, Np) to compute_control:","category":"page"},{"location":"manual/objective/","page":"Objective function","title":"Objective function","text":"r_trajectory = [1.0 1.5 2.0 2.0 2.0;   # Reference for output 1\n                0.0 0.0 0.5 1.0 1.0]   # Reference for output 2  \nu = compute_control(mpc, x; r=r_trajectory)","category":"page"},{"location":"manual/simple/#man_simple","page":"Simple example","title":"Simple Example","text":"","category":"section"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"A simplified form of the MPC problem that LinearMPC.jl solves is","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"beginaligned\n        undersetu_0dotsu_N-1textminimize frac12sum_k=0^N-1 left((Cx_k-r)^T Q (C x_k-r) + u_k^T R u_k + Delta u_k^T R_r Delta u_kright)\n        textsubject to  x_k+1 = F x_k + G u_k quad k=0dots N-1\n         x_0 = hatx \n         underlineb leq A_x x_k + A_u u_k  leq overlineb quad k=0 dots N-1\nendaligned","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"Consider now the specific case when we have a given dynamical system x_k+1 = F x_k + G u_k with","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"F triangleq beginbmatrix\n1  05  \n0  1\nendbmatrixquad\nG triangleq beginbmatrix\n0   \n1\nendbmatrix","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"The quantities that we want to control are y_1 = x_1, and y_2 = x_1+x_2, which can be put on the form y = C x with","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"C triangleq  beginbmatrix\n1  0    \n1  1\nendbmatrix","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"and the weights of the objective are","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"Q triangleq  beginbmatrix\n1  0    \n0  1\nendbmatrixquad\nR = 0 quad\nRr= 1","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"Moreover, we assume that we have the input constraint -3 leq u leq 3, and the output constraints  0 leq y_1 leq 1, and 0 leq y_2 leq 2. Finally, we have the constraint -1 leq 2 x_1 - x_2 leq 2.","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"We can create an MPC controller for the corresponding problem with the following code: ","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"using LinearMPC\n\n# dynamics\nF = [1 0.5; 0 1]\nG = [0;1]\n\n# create mpc struct\nmpc  = LinearMPC.MPC(F,G; C=[1 0; 1  1])\n\n# objective\nset_objective!(mpc, Q=[1,1], R=0, Rr = [1])\n\n# add constraints\nset_bounds!(mpc,umin=[-3],umax=[3], ymin= [0, 0],ymax = [1,2])\nadd_constraint!(mpc,Ax = [2 -1], lb = [-1], ub = [2])\n\n# the prediction/control horizons\nset_horizon!(mpc,10)","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"where the last command set_horizon!(mpc,10) sets the prediction horizon of the controller to 10 time steps.","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"That is it! Let's try our MPC controller.","category":"page"},{"location":"manual/simple/#Testing-the-MPC-controller-in-simulation","page":"Simple example","title":"Testing the MPC controller in simulation","text":"","category":"section"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"The function compute_control(mpc,x;r) uses the MPC controller mpc to compute an optimal control action given the state x and reference value r. For example,","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"u = compute_control(mpc,[0.5,1];r=[0,0])","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"gives that the optimal control action at x=[0.5,1] with r=[0,0] is u=-1.","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"Still, it is hard to draw any conclusion about wheter the controller is doing what we desire based on solving just one problem. To give a better feel of the performance of the MPC, we can create a Simulation for it. The following code simulates the closed-loop system, starting at x0=[0,0], with a reference value r=[1,0], for N=10 time steps:","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"# simulate the system\nsim = LinearMPC.Simulation(mpc;x0=[0,0],r=[1,0],N=10)\n","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"To visualize the result we can use the plotting package Plots:","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"using Plots\nplot(sim)\n","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"<p><img src=\"../../assets/simple_sim1.svg\" alt=\"simple_sim1\" width=700 style=\"background-color:white; \n    border:20px solid white; display: block; margin-left: auto; margin-right: auto;\"/></p>","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"We can see that both of the output are not following the references very well. This is due to the  desired value r=[1,0] not satisfying the constraints, which makes it impossible to reach it. If we, however, mainly want  y_1 to reach its reference, we can increase the weight of y_1 from 1 to 1000: ","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"set_objective!(mpc, Q=[1000, 1], Rr = [1])\nsim = LinearMPC.Simulation(mpc;x0=[0,0],r=[1,0],N=10)\nplot(sim)","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"<p><img src=\"../../assets/simple_sim2.svg\" alt=\"simple_sim2\" width=700 style=\"background-color:white; \n    border:20px solid white; display: block; margin-left: auto; margin-right: auto;\"/></p>","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"This gives the desired effect, since now y_1 is able to follow its reference. The output y_2 still don't reach its reference value of 0 due to the constraint -1leq 2 x_1 - x_2 leq 2. With the controller doing what we want, it is ready to be deployed in practice! ","category":"page"},{"location":"manual/simple/#Code-generation","page":"Simple example","title":"Code generation","text":"","category":"section"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"Most real-time controllers run on embedded hardware, which often require the controller to be implemented in a low-level programmign language like C. However, implementing an MPC controller in C from scratch is a very time consuming endeveaur. To simplify the process, LinearMPC.jl can generate C-code for MPC controllers that have been designed and tested in Julia, which enables the MPC controller to easibly be applied on embedded systems. To generate such C code in a directory code_dir, we can run the following code","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"LinearMPC.codegen(mpc; dir=\"code_dir\", fname=\"test_mpc\")","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"where fname determines some of the naming of the generated code.","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"The main function of interest (located in {fname}.h) is mpc_compute_control(control, state, reference, disturbance). This function computes the optimal control given the current state, reference, and measured disturbances disturbance, which are all floating-point arrays. The optimal control is stored in the floating-point array control.","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"note: Previous control action\nIf there is a penalty on the change in of control actions Delta u, the function mpc_compute_control uses the value that is in control as the previous control action uprev. ","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"To run a quick test of the generated code, let's test to compute a control for x=[0,0] and r=[1,0]. We do this with the following C-code, which we put in a file called test.c:","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"#include \"test_mpc.h\" \n#include <stdio.h>\nint main(){\n    // initialize \n    c_float control[1] = {0};\n    c_float state[2] = {0,0};\n    c_float reference[2] = {1,0};\n \n    // Get the control at the current state/reference \n    mpc_compute_control(control,state,reference,NULL);\n\n    // print the computed control\n    printf(\"the control is: %f\\n\", control[0]);\n}","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"where the #include \"test_mpc.h\" comes from our selection of fname (and the inclusion of stdio is just necessary for printing in the example code.) ","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"Let's compile the code with GCC by running the following commands in a terminal: ","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"gcc *.c -o test.out","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"If we run the example with ./test.out we get the following output","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"the control is: 1.000000","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"which matches the control computed by the controller at the first time step in the second simulation above. Hence, the MPC controller seems to work as expected. ","category":"page"},{"location":"manual/simple/","page":"Simple example","title":"Simple example","text":"How the values of state,reference, and disturbance in the generated C-code are set depends on the particular application. For example, state might come from a state observer, and reference might come from some motion planner or user interface.","category":"page"},{"location":"manual/constraints/#man_constraints","page":"Constraints","title":"Constraints","text":"","category":"section"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"The constraints that are supported in LinearMPC.jl are of the form ","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"underlineb leq A_x x_k + A_u u_k leq overlineb","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"Such constraints can be added with the function add_constraint!.","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"Bounds on controls (underlineu leq u leq overlineu) and on outputs (underliney leq y leq overliney) can be set in a special way with the function set_bounds!.","category":"page"},{"location":"manual/constraints/#Illustrative-example","page":"Constraints","title":"Illustrative example","text":"","category":"section"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"As an illustrative example, consider the case with two controls u_1 and u_2, two outputs y_1 and y_2, and three states x_1, x_2, and x_3, where we want to impose the following constraints","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"beginaligned\n-2 leq u_1 leq 1  \n0 leq u_2 leq 3 \n-1 leq y_1 leq 1  \n-3 leq y_2 leq 0 \n-1 leq x_2 - 3 x_3 leq 5 \n-1 leq x_1 - 2 x_2 + u_2 leq 1\nendaligned","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"This can be added to an MPC controller mpc with the following commands","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"# control + output bounds\nset_bounds!(mpc;umin=[-2,0], umax = [1,3], ymin = [-1,-3], ymax = [1,0])\n\n# -1 ≤ x2 - 3 x3 ≤  5 \nadd_constraint!(mpc; Ax = [1 0 3], lb = -2, ub = 5)\n\n# -1 ≤ x1 - 2 x2 + u2 ≤  1\nadd_constraint!(mpc; Ax = [1 -2 0], Au = [0 1], lb = -1, ub = 1)","category":"page"},{"location":"manual/constraints/#Constraint-horizon","page":"Constraints","title":"Constraint horizon","text":"","category":"section"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"The constraints from above will be enforced for all time steps up until the prediction horizon. It is, however, possible to specify a limited subset of time steps when a constraint should be satisfied. In other words, constraints are of the form","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"underlineb leq A_x x_k + A_u u_k leq overlinebqquad  textfor all  kin mathcalK","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"where the index set mathcalK subseteq 1dotsN_p determines for which time steps the constraint should be enforced. By default mathcalK = 1dots N_p. The indices for which the constraints should be enforced are specified with the optional argument ks to add_constraint!.  ","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"For example, say that we want to add the constraint","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"-1 leq x_1 + x_2 + 3 x_3 leq 1 qquad k in 246","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"to the MPC controller mpc. This can be done with ","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"add_constraint!(mpc;Ax=[1 1 3], lb = -1, ub = 1, ks = [2,4,6])","category":"page"},{"location":"manual/constraints/#Soft-constraints","page":"Constraints","title":"Soft constraints","text":"","category":"section"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"To ensure that there is a solution to the resulting optimization problem, it can be good to soften some constraint. A soft constraints means that the constraints is allowed to be violated, but such violations are penalized. A constraint can be marked to be soft by setting the optional argument soft to true. For example, if the constraint from above should be soft, one could run the command ","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"add_constraint!(mpc;Ax=[1 1 3], lb = -1, ub = 1, ks = [2,4,6], soft=true)","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"By default, bound constraints on inputs u are hard, and bound constraint outputs y are soft.","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"To be more specific, a constraint underlineb leq A_x x_k + A_u u_k leq overlineb is softened by introducing a slack variable epsilon, and replace the constraint with the constraints ","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"beginaligned\nunderlineb-epsilon leq A_x x_k + A_u u_k  \n A_x x_k + A_u u_k leq overlineb + epsilon\nendaligned","category":"page"},{"location":"manual/constraints/","page":"Constraints","title":"Constraints","text":"To penalize violation of the constraint, a term rho epsilon is added to the objective function, where the weight rho determines how hard the soft constraints should be penalized. By default, rho is set to 1e6. ","category":"page"},{"location":"manual/prestab/#man_prestabl","page":"Prestabilization","title":"Prestabilization","text":"","category":"section"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"The optimization problem that is solved is obtained by simulating the system forward using the dynamics","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"x_k+1 = F x_k + G u_k","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"This might lead to an ill-conditioned optimization problem if F is unstable and the prediction horizon is long. To mitigate numerical problems, one can use a prestabilizing feedback, which reparametrizes u with a new decision variable v and a feedback gain K as","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"u_k = -K x_k +v_k","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"This gives the new closed-loop system","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"x_k+1 = (F-GK) x_k + G v_k","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"If K is selected such that F-GK is stable, the condensed Quadratic program will be better conditioned compared to the unstable F.","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"In LinearMPC.jl you can set a stabilizing feedback K for an MPC controller mpc with","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"set_stabilizing_feedback!(mpc,K)","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"A popular choice of K is as the gain from solving an infinite horizon LQR problem. This gain can be set as the stabilizing feedback with","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"set_stabilizing_feedback!(mpc)","category":"page"},{"location":"manual/prestab/#Example","page":"Prestabilization","title":"Example","text":"","category":"section"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"Consider a first-order system with a pole in 10, which has the transfer function  ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"G(s) = frac10s-10","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"Let's create an MPC controller with prediction horizon N_p = 50 and sample time T_s = 01 seconds for this system:","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"using LinearMPC\nusing ControlSystemsBase\n\nsys = tf([1],[1, -10])\nmpc = LinearMPC.MPC(sys;Np=50, Ts=0.1)\nset_objective!(mpc;Q=1,Rr=1,R=0)","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"Moreover, we set the weights Q = 1 and R_r = 1 to be able to track references.","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"If we try to simulate the system with this controller for N=100 time steps with the setpoint r=1 ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"sim = LinearMPC.Simulation(mpc;r=[1],N=100)","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"we get an error telling us \"Could not setup optimization problem\". The reason for this error is that the resulting optimization problem is very ill-conditioned, and cannot handled by the optimization solver. ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"To see this more closely, we can check the condition number for the Hessian of the resulting optimization problem: ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"using LinearAlgebra\noptimization_problem = LinearMPC.mpc2mpqp(mpc)\ndisplay(cond(optimization_problem.H))","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"which is around 1e43. This is a very ill-conditioned problem (typically condition numbers above approx 1e6 might lead to numerical problems.) ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"To make the optimization problems better conditioned, we can add a prestabilizing feedback: ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"set_prestabilizing_feedback!(mpc)","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"Now if we check the condition number again ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"optimization_problem = LinearMPC.mpc2mpqp(mpc)\ndisplay(cond(optimization_problem.H))\n","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"we get that it is approx 8e2, which is a striking improvement! Now, if we simulate the system again, but with our updated controller, we get that the output successfully tracks the reference r=1. ","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"sim = LinearMPC.Simulation(mpc;r=[1],N=100)\nusing Plots\nplot(sim)","category":"page"},{"location":"manual/prestab/","page":"Prestabilization","title":"Prestabilization","text":"<p><img src=\"../../assets/step_prestab.svg\" alt=\"simple_sim1\" width=700 style=\"background-color:white; \n    border:20px solid white; display: block; margin-left: auto; margin-right: auto;\"/></p>","category":"page"},{"location":"#LinearMPC.jl","page":"Home","title":"LinearMPC.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"note: Documentation under development\nThe documentation for LineaerMPC.jl is currently under development","category":"page"},{"location":"","page":"Home","title":"Home","text":"The focus of LinearMPC.jl is Model Predictive Control (MPC) of linear systems. The aim of the package is to produce high-performant and lightweight C-code that can easily be used on embedded systems, while at the same time give a user-friendly and expressive development environment for MPC. The package supports code generation for the Quadratic Programming solver DAQP, and for explicit solutions computed by ParametricDAQP.jl.","category":"page"},{"location":"#Model-Predictive-Control","page":"Home","title":"Model Predictive Control","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In MPC, an optimal control decision is computed at every sampling instance by solving an optimization probelm. On a high-level, the optimization problems solved are of the form","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginaligned\n        undersetu_0dotsu_N-1textminimize textcolorpurplefrac12sum_k=0^N-1 left((Cx_k-r)^T Q (C x_k-r) + u_k^T R u_k + Delta u_k^T R_r Delta u_kright)\n        textsubject to textcolorbluex_k+1 = F x_k + G u_k quad k=0dots N-1\n         textcolorredx_0 = hatx \n         textcolorgreenunderlineb leq A_x x_k + A_u u_k  leq overlineb quad k=0 dots N-1\nendaligned","category":"page"},{"location":"","page":"Home","title":"Home","text":"where an textcolorpurpletextobjective is minimized , subject to a textcolorbluetextdynamical system that is simulated over a horizon N, textcolorredtextstarting from an estimate hatx of the current state. Additionally, textcolorgreentextconstraints like actuator limits and state constraints are accounted for. The objective is comprised by the deviation of an output y= Cx from a reference value r, the control effort (u^T R u) , and the change of the control action Delta u^T R_r Delta u. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"LinearMPC.jl generates a condensed problem by eliminating the equality constraint. The resuliting optimization problem is a dense Quadratic Program (QP). LinearMPC.jl uses the QP sovler DAQP, a dual active-set solver that has been specialized to solved such problems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The solution map for the optimization problem is a piecewise affine function over polyhedral regions. LinearMPC.jl supports the computation of such explicit solutions by interfacing the multi-parameteric QP solver ParametricDAQP.jl","category":"page"},{"location":"#Why-LinearMPC.jl?","page":"Home","title":"Why LinearMPC.jl?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Code generation of high-performant, allocation-free, library-free, and lightweight C-code that can be embedded on any micro controller. \nState-of-the-art computation of explicit solutions (~100x faster than other software packages)  \nTools to determine real-time certificates of the complexity of the solver, allowing for MPC in with guarantees on the memory and computational requirements before deploying the solver.","category":"page"},{"location":"#Why-not-LinearMPC.jl?","page":"Home","title":"Why not LinearMPC.jl?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"As its name suggests, the package is specialized for MPC for linear systems. If a linear (or linearized) model does not suffice for your use case, consider the following packages.","category":"page"},{"location":"","page":"Home","title":"Home","text":"ModelPredictiveControl.jl - A high-level MPC packages in Julia. While it does not generate embeddable C-code, it is an excellent package during development of MPC controllers. \nacados - provides fast and embedded solvers for nonlinear optimal control, specifically designed for real-time applications and embedded systems. This is the current state-of-the art if you are interested in real-time nonlinear MPC on embedded systems. \nAre you more of a Python person? You can still use LinearMPC.jl through its sister package lmpc.","category":"page"}]
}
